# _When Video Coding Meets Multimodal Large Language Models: A Unified Paradigm for Video Coding_

- Link to Article: [https://arxiv.org/abs/2408.08093v1](https://arxiv.org/abs/2408.08093v1)

üìç This paper introduces a groundbreaking approach to video coding by integrating Multimodal Large Language Models (MLLMs) into the process, creating a unified Cross-Modality Video Coding (CMVC) paradigm. This novel framework significantly enhances video compression efficiency while maintaining both semantic and perceptual quality, especially in Ultra-Low Bitrate (ULB) and Extremely-Low Bitrate (ELB) scenarios.

üî∏ _Challenges in Video Compression_: Traditional video codecs often struggle to preserve essential semantic information when compressing video at high ratios, resulting in poor video quality. Additionally, the complexity of temporal information in videos poses a challenge for effective compression, particularly in scenarios requiring ULB and ELB settings.

üî∏ _Capabilities of the CMVC Framework_: The CMVC framework leverages the advanced capabilities of MLLMs to represent both content and motion in videos through multimodal representations. By employing different encoding-decoding modes such as Text-Text-to-Video (TT2V) and Image-Text-to-Video (IT2V), CMVC ensures high-quality semantic and perceptual video reconstruction. These modes offer flexibility, allowing for optimal video compression and reconstruction tailored to specific needs.

üî∏ _Performance and Flexibility_: Experiments conducted on various benchmarks demonstrate that the CMVC framework outperforms traditional codecs, achieving superior video quality at significantly lower bitrates. The TT2V mode excels in semantic reconstruction, while the IT2V mode offers enhanced perceptual consistency. The integration of state-of-the-art models like VideoCrafter and AnimateDiff further bolsters the performance, making CMVC a versatile solution for diverse video coding requirements.

üî∏ _Impact and Future Directions_: The CMVC paradigm represents a significant advancement in video coding technology, particularly in contexts where preserving video quality at minimal bitrates is crucial. Future research will likely explore additional encoding-decoding modes and integrate more sophisticated control mechanisms to further enhance video reconstruction quality across all bitrate levels.

üî∏ _Contribution to the Field_: By introducing a unified framework that marries video coding with MLLMs, this research sets a new standard in the field. The CMVC paradigm not only addresses the limitations of existing codecs but also opens up new possibilities for efficient and high-quality video compression, which is essential for applications ranging from streaming to video archiving.

### Reference:

Zhang, P., Li, J., Wang, M., Sebe, N., Kwong, S., Wang, S., 2024. When Video Coding Meets Multimodal Large Language Models: A Unified Paradigm for Video Coding. arXiv:2408.08093v1. Available at: [https://arxiv.org/abs/2408.08093v1](https://arxiv.org/abs/2408.08093v1).
Zijian Yang

ORCiD: 0009-0006-8301-7634

------

Revolutionizing Text-to-Image Synthesis: Enhancing User Interaction with Multi-Turn Prompt Generation

**Article link:** https://arxiv.org/abs/2408.12910

ðŸ“ŒText-to-image synthesis (TIS) models have dramatically transformed digital image creation by converting textual descriptions into high-quality visuals. However, the reliance on user-generated prompts poses a challenge, especially for novice users. The paper introduces DialPrompt, a novel solution designed to enhance user engagement and control in this process.

ðŸ”¹DialPrompt addresses the limitations of existing single-turn TIS models, which often lack interpretability and user interaction. By conducting multiple rounds of dialogue, this model gathers user preferences, allowing for a more tailored and interactive prompt generation experience. This innovation is particularly crucial in overcoming the challenges faced by novice users in crafting effective prompts.

ðŸ”¹The core innovation of DialPrompt lies in its ability to identify 15 essential dimensions that contribute to high-quality TIS prompts. By guiding users through these dimensions in a step-by-step dialogue, the model ensures that each prompt is optimized for the desired visual output. This approach significantly improves the interpretability and personalization of the generated images.

ðŸ”¹Experimental results demonstrate that DialPrompt outperforms traditional prompt generation methods by a significant margin. Users rated it 46.5% higher in user-centricity compared to existing models, and it achieved a 5.7% improvement in image quality. These results highlight the effectiveness of DialPrompt in creating more visually satisfying and user-aligned outputs.

ðŸ”¹DialPromptâ€™s ability to enhance user experience in TIS models opens new possibilities for both novice and advanced users. By offering greater control and transparency in the prompt generation process, this model paves the way for more intuitive and satisfying interactions with AI-driven creative tools. The future of TIS could see even more sophisticated models built on this foundation.

Liu, Y., He, M., Yao, F., Ji, Y., Tao, S., Du, J., Li, D., Gao, J., Zhang, L., Yang, H., Chen, B., & Yoshie, O. (2024). What Do You Want? User-centric Prompt Generation for Text-to-image Synthesis via Multi-turn Guidance. [ArXiv.org](http://ArXiv.org). https://arxiv.org/abs/2408.12910
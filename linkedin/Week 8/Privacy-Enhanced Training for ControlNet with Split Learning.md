Privacy-Enhanced Training for ControlNet with Split Learning

Author: [Wendi Fan](https://www.linkedin.com/in/wendi-fan-265996310/) (**ORCID: 0000-0003-0284-9166**)

ðŸ“Œ This paper introduces a new method aimed at enhancing data privacy in the training of ControlNet and Stable Diffusion models using split learning. With the rise of large generative models like ControlNet, a key issue is ensuring that users' private data remains protected when training on distributed devices. Conventional methods like federated learning and split learning present privacy challenges. This study proposes a privacy-preserving structure, which eliminates the need for gradient back-propagation to clients, and incorporates innovative mechanisms to safeguard image and text data without compromising performance.

Article link: https://arxiv.org/abs/2409.08503

ðŸ”¹ The paper addresses the challenge of training ControlNet models while ensuring the privacy of users' distributed data. Current approaches like federated learning struggle with the large GPU resources required, and split learning is vulnerable to attacks that can reconstruct private data from transmitted features. There is a strong need for a solution that balances data privacy and computational efficiency.

ðŸ”¹ The authors propose a new deployment structure that removes the need for the server to send gradients back to the client, thus improving efficiency. Additionally, they design privacy-preserving mechanisms like timestep sampling policies and activation functions that protect users' data during the forward diffusion process. This structure supports the secure fine-tuning of ControlNet models across distributed devices while maintaining high image generation quality.

ðŸ”¹The new framework significantly improves both the efficiency of distributed training and the privacy of users' data. Attacks that attempt to reconstruct private data are shown to be largely ineffective with this approach, while the image generation quality remains uncompromised. The system also demonstrates reduced communication overhead and lower GPU memory requirements for clients.

ðŸ”¹ The paper concludes that the proposed structure provides a strong balance between privacy and efficiency in distributed learning. Future work may focus on further optimizing the trade-offs between privacy and performance, particularly in handling complex datasets or additional types of private data, and extending the framework to other generative modelsâ€‹

ðŸ“‘ Yao, D. (2024).  Enhancing Privacy in ControlNet and Stable Diffusion via Split Learning. DOI: 10.48550/arXiv.2409.08503.
Header image:

![](https://cdn.jsdelivr.net/gh/data-community-of-practice/AI-Graph-Obsidian@main/img/202408312223463.png)

Tags: AI, LLM, Viggle, Runway

# Viggle AI: Revolutionizing Digital Creativity with Controllable Video Generation

## How a 15-Member Startup is Empowering Millions to Turn Imagination into Reality with AI-Driven Visual Content

## Authors

- [Zijian Yang](https://www.linkedin.com/in/zijian-yang/) (**ORCID:** [0009-0006-8301-7634](https://orcid.org/0009-0006-8301-7634))

## Introduction

Viggle AI, a startup known for its eponymous video generation service, recently announced the completion of a $19 million early-stage investment, led by Andreessen Horowitz.

The company's founder and CEO, Chu Hang, is of Chinese descent and has worked at Google, NVIDIA, Facebook, and Autodesk.

You might not be familiar with Viggle AI, but you've probably seen its viral memes online. These include the widely circulated meme where rapper Lil Yachty is jumping at a summer music festival, but his face is replaced with Joaquin Phoenix's Joker from the movie "Joker."

![](https://cdn.jsdelivr.net/gh/data-community-of-practice/AI-Graph-Obsidian@main/img/202408312241401.gif)

Jesus seems to be cheering on the crowd:

![](https://cdn.jsdelivr.net/gh/data-community-of-practice/AI-Graph-Obsidian@main/img/202408312236145.gif)

Viggle initially started from the Discord community and currently has over 4.3 million users. In March, they launched an independent app. The team developed their own JST-1 model, which supports creating more realistic character movements and expressions.

In today's article, we will explore how Viggle, a small team founded by Chinese entrepreneurs, achieved "viral" user growth and the insights from the founder's interview with a16z.

## How a 15-Member Team Created a Global Community with Viral Growth

In March 2024, Viggle launched its beta testing phase, attracting over 4 million users to its Discord community, where they gather to create and play with derivative works.

Currently, Viggle's user base consists of two main groups:

1. **Social Media Enthusiasts**: These users want to create entertaining memes and seek social engagement. Viggle's highly appealing special effects inspire these users to experiment and then share their creations through social channels, driving viral growth. This is one of the best ways to increase product visibility.
2. **Professional Creators**: These users utilize Viggle to design games and create visual effects. For example, animation engineers can quickly turn concepts into rough animations, visualizing ideas and feelings, significantly reducing design draft time, streamlining workflows, and boosting efficiency.

Viggle's team members are passionate and highly skilled. Founder Chu Hang has held AI researcher positions at leading global tech companies such as Autodesk, Facebook, Nvidia, and Google. He earned a bachelor's degree in Information Engineering from Shanghai Jiao Tong University, pursued a master's degree in Electrical and Computer Engineering at Cornell University, and conducted research at the Advanced Multimedia Processing Lab. In 2016, Chu Hang joined the University of Toronto to pursue a Ph.D. in Computer Science, focusing on machine learning research.

Over the past eight months, Nan Ha has served as the head of product growth at Viggle. She is an expert in SEO, content marketing, and affiliate marketing partnerships, having graduated from the joint USC and LSE master's program in Global Communication and Media. Under her leadership, Viggle's Discord community rapidly expanded from 500 members to over 4 million, making it the second-largest community globally.

By operating on the Discord platform, Viggle quickly expanded its user base and leveraged Discord's content moderation and community management tools to handle its massive user group. Discord's immediacy and interactivity better support Viggle's viral spread and user growth.

For startups like Viggle and Midjourney, operating on Discord means they don't need to build a separate user platform. Instead, they can tap into Discord's tech-savvy user base and built-in content moderation tools. For Viggle, with only 15 employees, this support is crucial.

Ben Shanken, Discord's VP of Product, commented, "No one is prepared for such growth. We chose to partner with them during their wide dissemination phase because they are still a startup. In fact, there's a lot of generative AI content on Discord."

Viggle has also achieved widespread reach on TikTok.

Under the hashtag #Viggle, there are over 40,000 videos, and under #viggleai, there are more than 33,000 videos, showing strong user engagement.

For instance, TikTok influencer Geirill, with 6,030 followers, received 416,000 likes, with Viggle AI videos accounting for 314,000 likes alone. Promotions by KOLs and influencers have brought significant traffic to Viggle, and users enjoy creating videos with Viggle, further promoting product dissemination and viral effects.

![Image Source: TikTok](https://cdn.jsdelivr.net/gh/data-community-of-practice/AI-Graph-Obsidian@main/img/202408312230085.webp)

Image Source: TikTok

Viggle's low barrier to entry allows both ordinary users and amateur creators to easily get started. This broad user base and convenient creation experience are among the key reasons for Viggle's explosive growth within the Discord community and on TikTok.

## Memes Are Just a Small Part of What Users Create

These various versions of memes are all created by users, but the original materials are provided by Viggle AI.

"Our model is fundamentally different from traditional video generators. Existing video generators are primarily pixel-based and do not understand physical structures. We enable our model to understand these, which significantly improves controllability and generation efficiency," said CEO Chu Hang.

For example, to create a video of a character like the Joker singing and dancing, you only need to upload a video containing the singing and dancing actions, along with an image of the character.

![](https://cdn.jsdelivr.net/gh/data-community-of-practice/AI-Graph-Obsidian@main/img/202408312230887.gif)

Alternatively, users can upload a character image and add a text prompt directly.

![](https://cdn.jsdelivr.net/gh/data-community-of-practice/AI-Graph-Obsidian@main/img/202408312231974.gif)

It's also possible to create animated characters entirely using text prompts.

![](https://cdn.jsdelivr.net/gh/data-community-of-practice/AI-Graph-Obsidian@main/img/202408312231078.gif)

Additionally, you can stylize real photos and add animations to them.

![](https://cdn.jsdelivr.net/gh/data-community-of-practice/AI-Graph-Obsidian@main/img/202408312231308.gif)

Creating memes is only a small part of Viggle users' needs. Currently, the videos it generates are far from perfect: characters often twitch incessantly and show no facial expressions. However, Viggle has already become a favored visualization tool for creative professionals. For filmmakers, animators, and video game designers, Viggle allows them to directly transform their ideas into visual effects.

One source of training materials for Viggle's AI model is YouTube videos. In media interviews, the CEO revealed that they have relied on public data so far, including YouTube videos. This statement is similar to what OpenAI CTO Mira Murati said about training Sora with data.

This could become an issue. In April of this year, YouTube's CEO stated that using YouTube videos to train text-to-video AI "clearly violates" their terms of service. This is true for Sora and might also be the case for Viggle.

Subsequently, a Viggle spokesperson clarified to the media: Viggle utilizes various public resources, including YouTube, to generate AI content. Our training data is meticulously curated and refined to ensure the entire process complies with all terms of service. We prioritize maintaining good relationships with platforms like YouTube and are committed to adhering to their terms, avoiding mass downloads and any other actions involving unauthorized video downloads.

This still seems to contradict YouTube's comments from April. Reportedly, many AI model developers, including OpenAI, Nvidia, Apple, and Anthropic, have used YouTube video transcriptions or clips to train their models.

This might be one of Silicon Valley's not-so-secret secrets: everyone might be doing it, but few are willing to say it out loud.

## Highly Controllable and Timely Video Generation

Traditionally, video and 3D generation have been seen as two separate challenges. Viggle has successfully addressed two key issues in generative video technology—high latency and low controllability—by adopting an innovative joint solution.

**Controllability**

Compared to other purely generative AI products like Runway and Sora, Viggle offers higher controllability and predictability. When using Runway, users generate videos by inputting a prompt, but they cannot predict the final result and often need multiple attempts to achieve the desired effect, lacking control over the generation process. Viggle allows users to upload existing videos and images, clearly indicating their expectations for the final generated video. By learning from the templates and actions in the uploaded videos, Viggle quickly and accurately produces the video content users envision, addressing the common controllability issues found in other AI video generation tools. This makes Viggle a better choice for video professionals and AI creators, especially in scenarios where quality and realistic physical effects are crucial.

**Low Latency**

Viggle's unique JST-1 technology unifies video and 3D generation within a single foundational model, significantly reducing video generation latency. This unified model can effectively utilize 3D spatial information and temporal dynamics, minimizing the redundancy and delay associated with traditional methods that handle these processes separately. Consequently, users no longer need to wait minutes or hours to obtain a few seconds of video.

JST-1 serves as the driving force, enabling the video-3D foundational model to analyze actions and poses from existing 2D video materials and construct 3D models. This process not only involves shape and appearance transformation but also includes a physical understanding of character movements and environmental interactions.

**Exploring Cross-Domain Applications and Enhancing Animation Production Efficiency**

Viggle also plans to continue improving its technology and expanding its functionalities. Chu stated, "We focus on building the backend service model while leveraging Discord's frontend infrastructure. This approach allows us to iterate faster and concentrate on developing the most advanced AI systems."

Additionally, the company is exploring multiple application scenarios beyond entertainment, such as in game design and visual effects. With Viggle, animation teams can quickly generate preliminary animation assets from concept designs, saving time and effort. This has the potential to revolutionize animation production, making it more efficient and user-friendly.

![Image Source: Viggle](https://cdn.jsdelivr.net/gh/data-community-of-practice/AI-Graph-Obsidian@main/img/202408312231074.png)

Image Source: Viggle

## Founder: Beyond Pixels, Focus on Precision in AI Generation Process

![](https://cdn.jsdelivr.net/gh/data-community-of-practice/AI-Graph-Obsidian@main/img/202408312232264.png)

Chu Hang: Currently, I am leading a project called Viggle, which we refer to as "controllable video generation." Unlike existing text-to-video conversion tools on the market, we aim to provide more precise control. Our goal is to allow users to specify actions and characters accurately.

Our team has previously been heavy users of image and video generation tools, but the biggest challenge we faced was that they were too difficult to learn, with a steep learning curve. Therefore, we hope that Viggle can be simple and easy to use, allowing everyone to get started easily without a complex learning process.

The basic functionality of Viggle is straightforward. You just need to upload two things: an image to define the character, and either text or a video to indicate the desired action. Then, Viggle combines these inputs to generate footage of the character performing the specified action. Initially, we intended this for filmmakers and game developers to quickly preview animation effects. This tool is indeed quite practical, and we have seen early users already utilizing it in this way.

However, what we didn't anticipate was that it would become a popular tool for creating memes. For instance, there's a template of a clown taking the stage, which users can replace with themselves in the video. We have observed millions of characters mimicking and recreating this moment.

It's also convenient to use. You upload an image, and within seconds, it appears in the scene. This diversity is quite interesting. We hope Viggle can adapt to such diverse use cases.

Some content creators have also reached out to us, asking if they can showcase their dances or songs on Viggle and hoping to collaborate with us for promotion. This is quite exciting as well.

Now, we are not limited to uploading videos to create content; we can use various templates. You can see that we have many templates here, including some with fun dance moves and sports event scenes.

For example, if you want to use a specific template and we already have the character, you can generate new content with that character and template. Even if you provide only a frontal image, our model will strive to generate a 360-degree full-body view. Our creator community has provided many excellent templates, and true diversity comes from those creative ideas.

For us, the most important thing is to support these creative communities, ensuring they have the tools they need, and the best ones at that. We want them to experience new features early on, almost through an exclusive channel. We are essentially providing the strongest support for the creator community.

We genuinely hope to apply this character modeling to more real-life scenarios, objects, and environments.

In my view, there are mainly two paths to achieving real-world modeling. One is a pixel-level approach, where Transformer models (Diffusion Models) have done quite well. However, there is an issue—it is difficult to control pixels. After all, the real world is three-dimensional and physical, and pixels are not an efficient way to express it. But its advantage is that it can train on any video to generate various content. We hope that when scaled up, controllability will naturally emerge. But we chose the other path.

We first achieve controllability as precise as a graphics engine, then expand from this foundation. So, I think the development of these two paths and how they eventually converge into an immersive experience is really exciting to anticipate.

Now, Viggle brings a whole new content consumption experience. For AI, usually, if you like a certain moment, you share it. But with Viggle, you can interact more deeply with that moment. For example, if I particularly like a certain moment, I can even place my virtual self into that scene to experience it. It's like entering a parallel universe where you can see how you would re-experience that moment. This new way of consuming content not only adds entertainment value but also brings a more personalized and customized experience.

If you want these creative contents to have real entertainment value, the technology must perform well. So, we take these humorous aspects seriously and conduct quite rigorous research.

## **Conclusion**

In conclusion, Viggle AI is not just pushing the boundaries of video generation technology; it's reshaping how we interact with digital content. By combining high controllability with low latency, Viggle enables creators—from casual meme enthusiasts to professional animators—to bring their ideas to life in ways previously unimaginable. The startup's rapid growth, fueled by its community-driven approach on platforms like Discord and TikTok, underscores the growing demand for accessible, yet powerful, creative tools. As Viggle continues to refine its technology and explore new applications, it stands at the forefront of a new era in content creation, where the lines between professional and amateur, reality and imagination, continue to blur. The future of digital creativity is here, and Viggle is leading the charge, turning pixels into possibilities.

## **Source**

- [https://techcrunch.com/2024/08/26/viggle-makes-controllable-ai-characters-for-memes-and-visualizing-ideas/](https://techcrunch.com/2024/08/26/viggle-makes-controllable-ai-characters-for-memes-and-visualizing-ideas/)
- [https://mp.weixin.qq.com/s/kHNmPYHNhhw5WngvzRcpgg](https://mp.weixin.qq.com/s/kHNmPYHNhhw5WngvzRcpgg)
- [https://www.youtube.com/watch?v=IebslwhPzFo&t=2s](https://www.youtube.com/watch?v=IebslwhPzFo&t=2s)
- [https://mp.weixin.qq.com/s/VGEcjWQ6pNPB1qO8eANtaA](https://mp.weixin.qq.com/s/VGEcjWQ6pNPB1qO8eANtaA)